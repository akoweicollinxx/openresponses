/**
 * Generated by Kubb (https://kubb.dev/).
 * Do not edit manually.
 */

import { allowedToolChoiceSchema } from "./allowedToolChoiceSchema.ts";
import { errorSchema } from "./errorSchema.ts";
import { functionToolChoiceSchema } from "./functionToolChoiceSchema.ts";
import { incompleteDetailsSchema } from "./incompleteDetailsSchema.ts";
import { itemFieldSchema } from "./itemFieldSchema.ts";
import { reasoningSchema } from "./reasoningSchema.ts";
import { textFieldSchema } from "./textFieldSchema.ts";
import { toolChoiceValueEnumSchema } from "./toolChoiceValueEnumSchema.ts";
import { toolSchema } from "./toolSchema.ts";
import { truncationEnumSchema } from "./truncationEnumSchema.ts";
import { usageSchema } from "./usageSchema.ts";
import { z } from "zod";

/**
 * @description The complete response object that was returned by the Responses API.
 */
export const responseResourceSchema = z
  .object({
    id: z.string().describe("The unique ID of the response that was created."),
    object: z
      .enum(["response"])
      .default("response")
      .describe("The object type, which was always `response`."),
    created_at: z
      .number()
      .int()
      .describe(
        "The Unix timestamp (in seconds) for when the response was created.",
      ),
    completed_at: z.union([z.number().int(), z.null()]),
    status: z.string().describe("The status that was set for the response."),
    incomplete_details: z.union([
      z.lazy(() => incompleteDetailsSchema).and(z.any()),
      z.null(),
    ]),
    model: z.string().describe("The model that generated this response."),
    previous_response_id: z.union([z.string(), z.null()]),
    instructions: z.union([z.string(), z.null()]),
    output: z
      .array(
        z
          .lazy(() => itemFieldSchema)
          .describe(
            "An item representing a message, tool call, tool output, reasoning, or other response element.",
          ),
      )
      .describe("The output items that were generated by the model."),
    error: z.union([z.lazy(() => errorSchema).and(z.any()), z.null()]),
    tools: z
      .array(
        z
          .lazy(() => toolSchema)
          .describe("A tool that can be used to generate a response."),
      )
      .describe(
        "The tools that were available to the model during response generation.",
      ),
    tool_choice: z.union([
      z.lazy(() => functionToolChoiceSchema),
      z.lazy(() => toolChoiceValueEnumSchema),
      z.lazy(() => allowedToolChoiceSchema),
    ]),
    truncation: z.lazy(() => truncationEnumSchema).and(z.any()),
    parallel_tool_calls: z
      .boolean()
      .describe(
        "Whether the model was allowed to call multiple tools in parallel.",
      ),
    text: z.lazy(() => textFieldSchema).and(z.any()),
    top_p: z
      .number()
      .describe(
        "The nucleus sampling parameter that was used for this response.",
      ),
    presence_penalty: z
      .number()
      .describe(
        "The presence penalty that was used to penalize new tokens based on whether they appear in the text so far.",
      ),
    frequency_penalty: z
      .number()
      .describe(
        "The frequency penalty that was used to penalize new tokens based on their frequency in the text so far.",
      ),
    top_logprobs: z
      .number()
      .int()
      .describe(
        "The number of most likely tokens that were returned at each position, along with their log probabilities.",
      ),
    temperature: z
      .number()
      .describe("The sampling temperature that was used for this response."),
    reasoning: z.union([z.lazy(() => reasoningSchema).and(z.any()), z.null()]),
    usage: z.union([z.lazy(() => usageSchema).and(z.any()), z.null()]),
    max_output_tokens: z.union([z.number().int(), z.null()]),
    max_tool_calls: z.union([z.number().int(), z.null()]),
    store: z
      .boolean()
      .describe(
        "Whether this response was stored so it can be retrieved later.",
      ),
    background: z
      .boolean()
      .describe("Whether this request was run in the background."),
    service_tier: z
      .string()
      .describe("The service tier that was used for this response."),
    metadata: z
      .any()
      .describe(
        "Developer-defined metadata that was associated with the response.",
      ),
    safety_identifier: z.union([z.string(), z.null()]),
    prompt_cache_key: z.union([z.string(), z.null()]),
  })
  .describe(
    "The complete response object that was returned by the Responses API.",
  );
